{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 9.242099,
     "end_time": "2023-10-31T22:04:31.187336",
     "exception": false,
     "start_time": "2023-10-31T22:04:21.945237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports all required libraries for data processing, model building, and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, LearningRateScheduler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics as metrics\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Sets up a learning rate scheduler that reduces the learning rate by 5% every epoch\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose = 0)\n",
    "\n",
    "# Walks through the directory '/kaggle/input' and its subdirectories, and joins the directory name and file name for each file found\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.136899,
     "end_time": "2023-10-31T22:04:31.330276",
     "exception": false,
     "start_time": "2023-10-31T22:04:31.193377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loads image file paths and labels, and creates a DataFrame for the dataset\n",
    "MildDemented_dir = r'/kaggle/input/alzheimers-mri-images/Processed Dataset/training/Mild Demented'\n",
    "ModerateDemented_dir = r'/kaggle/input/alzheimers-mri-images/Processed Dataset/training/Moderate Demented'\n",
    "NonDemented_dir = r'/kaggle/input/alzheimers-mri-images/Processed Dataset/training/Non Demented'\n",
    "VeryMildDemented_dir = r'/kaggle/input/alzheimers-mri-images/Processed Dataset/training/Very Mild Demented'\n",
    "\n",
    "filepaths = []\n",
    "labels = []\n",
    "dict_list = [MildDemented_dir, ModerateDemented_dir, NonDemented_dir, VeryMildDemented_dir]\n",
    "class_labels = ['Mild Demented', 'Moderate Demented', 'Non Demented', 'Very MildDemented']\n",
    "\n",
    "# Iterates over the directories containing MRI images for different stages of Alzheimer's disease\n",
    "for i, directory in enumerate(dict_list):\n",
    "    file_list = os.listdir(directory)\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        filepaths.append(file_path)\n",
    "        labels.append(class_labels[i])\n",
    "\n",
    "# Creates pandas Series for file paths and labels\n",
    "Fseries = pd.Series(filepaths, name = \"filepaths\")\n",
    "Lseries = pd.Series(labels, name = \"labels\")\n",
    "Alzheimer_data = pd.concat([Fseries, Lseries], axis = 1)\n",
    "Alzheimer_df = pd.DataFrame(Alzheimer_data)\n",
    "\n",
    "print(Alzheimer_df.head())\n",
    "print(Alzheimer_df[\"labels\"].value_counts())\n",
    "\n",
    "# Shows the shape of the DataFrame containing the dataset\n",
    "Alzheimer_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.022317,
     "end_time": "2023-10-31T22:04:31.379746",
     "exception": false,
     "start_time": "2023-10-31T22:04:31.357429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splits the dataset into training, validation, and test sets\n",
    "# The dataset is divided into three subsets: training, validation, and test\n",
    "# Initially, the data is split into training (70%) and test (30%) sets\n",
    "# Then, the training set is further divided into training (80%) and validation (20%) sets\n",
    "train_images, test_images = train_test_split(Alzheimer_df, test_size = 0.3, random_state = 42)\n",
    "train_set, val_set = train_test_split(Alzheimer_df, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Prints the shapes of the training, validation, and test sets\n",
    "# This code prints the number of samples in the training, validation, and test sets after the split\n",
    "print(train_set.shape)\n",
    "print(test_images.shape)\n",
    "print(val_set.shape)\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 14.260362,
     "end_time": "2023-10-31T22:04:45.665777",
     "exception": false,
     "start_time": "2023-10-31T22:04:31.405415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates ImageDataGenerators for training, validation, and test sets\n",
    "# Initializes three data generators for training, testing, and validation using ImageDataGenerator from Keras\n",
    "# Preprocesses the images by resizing and applying MobileNetV2's specific preprocessing\n",
    "# Loads data from dataframes with image file paths and labels\n",
    "# Sets color mode to 'rgb', class mode to 'categorical', and batch size to 32\n",
    "# Disables shuffling for all generators\n",
    "image_gen = ImageDataGenerator(preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "\n",
    "train = image_gen.flow_from_dataframe(\n",
    "    dataframe = train_set, x_col = \"filepaths\", y_col = \"labels\",\n",
    "    target_size = (244, 244),\n",
    "    class_mode = \"categorical\",\n",
    "    batch_size = 32,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "test = image_gen.flow_from_dataframe(\n",
    "    dataframe = test_images, x_col = \"filepaths\", y_col = \"labels\",\n",
    "    target_size = (244, 244),\n",
    "    class_mode = \"categorical\",\n",
    "    batch_size = 32,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "val = image_gen.flow_from_dataframe(\n",
    "    dataframe = val_set, x_col = \"filepaths\", y_col = \"labels\",\n",
    "    target_size = (244, 244),\n",
    "    class_mode = \"categorical\",\n",
    "    batch_size = 32,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code prints the class names that are used in the dataset\n",
    "# It retrieves the class indices from the 'train' object and lists the keys, which represent the class names\n",
    "# Finally, it prints out the list of class names\n",
    "classes = list(train.class_indices.keys())\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.015541,
     "end_time": "2023-10-31T22:04:45.707875",
     "exception": false,
     "start_time": "2023-10-31T22:04:45.692334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defines a function to display a batch of images with their class labels\n",
    "def show_knee_images(image_gen):\n",
    "    test_dict = test.class_indices\n",
    "    classes = list(test_dict.keys())\n",
    "    images, labels = next(image_gen)\n",
    "    plt.figure(figsize = (20, 20))\n",
    "    length = len(labels)\n",
    "\n",
    "    # Determines the number of images to display (up to 25)\n",
    "    if length < 25:\n",
    "        r = length\n",
    "    else:\n",
    "        r = 25\n",
    "    # Iterates over the images in the batch\n",
    "    for i in range(r):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        image = (images[i] + 1) / 2\n",
    "        plt.imshow(image)\n",
    "        index = np.argmax(labels[i])\n",
    "        class_name = classes[index]\n",
    "        plt.title(class_name, color = \"green\", fontsize = 16)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Displays a batch of training images with their class labels\n",
    "show_knee_images(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.490687,
     "end_time": "2023-10-31T22:04:52.054141",
     "exception": false,
     "start_time": "2023-10-31T22:04:48.563454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defines and compiles the CNN model architecture for multi-class classification\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters = 128, kernel_size = (8, 8), strides = (3, 3), activation = 'relu', input_shape = (224, 224, 3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2D(filters = 256, kernel_size = (5, 5), strides = (1, 1), activation = 'relu', padding = \"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size = (3, 3)),\n",
    "\n",
    "    keras.layers.Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), activation = 'relu', padding = \"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    k\n",
    "    eras.layers.Conv2D(filters = 256, kernel_size = (1, 1), strides = (1, 1), activation = 'relu', padding = \"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2D(filters = 256, kernel_size = (1, 1), strides = (1, 1), activation = 'relu', padding = \"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = \"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size = (2, 2)),\n",
    "\n",
    "    keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = \"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = \"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.MaxPool2D(pool_size = (2, 2)),\n",
    "\n",
    "    keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = \"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.MaxPool2D(pool_size = (2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "\n",
    "    keras.layers.Dense(1024, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    keras.layers.Dense(1024, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    keras.layers.Dense(4, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizes the model architecture and compiles the model\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = tf.optimizers.SGD(learning_rate = 0.001),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "# Trains the CNN model using the training and validation sets\n",
    "# Trains the CNN model using the provided training and validation datasets for 22 epochs\n",
    "# Specifies that validation should be performed after each epoch\n",
    "history = model.fit(train, epochs = 22, validation_data = val, validation_freq = 1)\n",
    "\n",
    "# Evaluates the trained model on the test set\n",
    "model.evaluate(test, verbose = 1)\n",
    "\n",
    "# Saves the trained model to a file\n",
    "model.save(\"alzheimer_model_cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2175.636942,
     "end_time": "2023-10-31T22:41:07.718861",
     "exception": false,
     "start_time": "2023-10-31T22:04:52.081919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generates predictions for the test set and decodes the predicted class labels\n",
    "pred = model.predict(test)\n",
    "pred = np.argmax(pred, axis = 1)  # Picks class with highest probability\n",
    "\n",
    "labels = (train.class_indices)\n",
    "labels = dict((v, k) for k, v in labels.items())\n",
    "\n",
    "pred2 = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.850022,
     "end_time": "2023-10-31T22:42:01.729607",
     "exception": false,
     "start_time": "2023-10-31T22:41:59.879585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizes the evolution of model accuracy and loss during training\n",
    "# Displays both metrics side by side for easy comparison between training and validation sets\n",
    "fig, axs = plt.subplots(1, 2, figsize = (14, 5))\n",
    "\n",
    "axs[0].plot(history.history['accuracy'])\n",
    "axs[0].plot(history.history['val_accuracy'])\n",
    "axs[0].set_title('Model Accuracy')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend(['Train', 'Val'], loc = 'upper left')\n",
    "\n",
    "axs[1].plot(history.history['loss'])\n",
    "axs[1].plot(history.history['val_loss'])\n",
    "axs[1].set_title('Model Loss')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend(['Train', 'Val'], loc = 'upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.857335,
     "end_time": "2023-10-31T22:42:05.111028",
     "exception": false,
     "start_time": "2023-10-31T22:42:03.253693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizes the loss curve for both training and validation sets\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc = 'upper left')\n",
    "plt.show()\n",
    "\n",
    "# Prints the classification report and accuracy score for the model predictions\n",
    "y_test = test_images.labels\n",
    "print(classification_report(y_test, pred2))\n",
    "print(\"Accuracy of the Model:\", \"{:.1f}%\".format(accuracy_score(y_test, pred2) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.932892,
     "end_time": "2023-10-31T22:42:12.030394",
     "exception": false,
     "start_time": "2023-10-31T22:42:10.097502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizes the confusion matrix as a heatmap with class labels\n",
    "# Defines the class labels\n",
    "class_labels = ['Mild Demented', 'Moderate Demented', 'Non Demented', 'Very MildDemented']\n",
    "\n",
    "# Calculates the confusion matrix\n",
    "cm = confusion_matrix(y_test, pred2)\n",
    "\n",
    "# Creates a figure and plots the confusion matrix as a heatmap\n",
    "plt.figure(figsize = (10, 5))\n",
    "sns.heatmap(cm, annot = True, fmt = 'g', vmin = 0, cmap = 'Blues', cbar = False)\n",
    "\n",
    "# Sets tick labels and axis labels\n",
    "plt.xticks(ticks = [0.5, 1.5, 2.5, 3.5], labels = class_labels, rotation = 30, ha = 'right', fontsize = 10)\n",
    "plt.yticks(ticks = [0.5, 1.5, 2.5, 3.5], labels = class_labels, rotation = 0, fontsize = 10)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6409027,
     "sourceId": 10349832,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2333.624247,
   "end_time": "2023-10-31T22:42:19.664070",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-31T22:03:26.039823",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
