{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports all required libraries for data handling, visualization, and building a TensorFlow CNN for multiclass image classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes TPU or default strategy for distributed training. Prints number of replicas and TensorFlow version\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 0.029776,
     "end_time": "2024-07-28T20:19:58.297159",
     "exception": false,
     "start_time": "2024-07-28T20:19:58.267383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sets main hyperparameters: batch size, image size, epochs, and enables data pipeline optimization\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "IMAGE_SIZE = [176, 208]\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 7.874879,
     "end_time": "2024-07-28T20:20:06.235553",
     "exception": false,
     "start_time": "2024-07-28T20:19:58.360674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loads and splits the dataset into training and validation sets, applies resizing and batching for model input\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/kaggle/input/alzheimers-mri-images/Processed Dataset/training\",\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = 1337,\n",
    "    image_size = IMAGE_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/kaggle/input/alzheimers-mri-images/Processed Dataset/training\",\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = 1337,\n",
    "    image_size = IMAGE_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.02965,
     "end_time": "2024-07-28T20:20:06.330658",
     "exception": false,
     "start_time": "2024-07-28T20:20:06.301008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defines class names for Alzheimer's MRI dataset\n",
    "class_names = ['Mild Demented', 'Moderate Demented', 'Non Demented', 'Very Mild Demented']\n",
    "\n",
    "# Assigns class names to training and validation datasets\n",
    "train_ds.class_names = class_names\n",
    "val_ds.class_names = class_names\n",
    "\n",
    "NUM_CLASSES = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.528411,
     "end_time": "2024-07-28T20:20:07.925073",
     "exception": false,
     "start_time": "2024-07-28T20:20:06.396662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Displays a sample of images from the training set with their class labels for visual inspection\n",
    "plt.figure(figsize = (10, 10))\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(train_ds.class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates and visualizes the number of images per class in the training set using a bar plot\n",
    "train_dir = \"/kaggle/input/alzheimers-mri-images/Processed Dataset/training\"\n",
    "\n",
    "# Counts the number of images in each class\n",
    "class_counts = {cls: len(os.listdir(os.path.join(train_dir, cls))) for cls in os.listdir(train_dir)}\n",
    "\n",
    "# Converts to DataFrame\n",
    "df = pd.DataFrame(list(class_counts.items()), columns = [\"Class\", \"Count\"])\n",
    "\n",
    "# Plots the number of images per class\n",
    "plt.figure(figsize = (15, 8))\n",
    "ax = sns.barplot(x = df[\"Class\"], y = df[\"Count\"], palette = \"Set1\")\n",
    "ax.set_xlabel(\"Class\", fontsize = 20)\n",
    "ax.set_ylabel(\"Count\", fontsize = 20)\n",
    "plt.title(\"The Number Of Samples For Each Class\", fontsize = 20)\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.087299,
     "end_time": "2024-07-28T20:20:08.094917",
     "exception": false,
     "start_time": "2024-07-28T20:20:08.007618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Applies one-hot encoding to the labels in the training and validation datasets for multiclass classification\n",
    "def one_hot_label(image, label):\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image, label\n",
    "\n",
    "# Applies one-hot encoding to training and validation datasets\n",
    "train_ds = train_ds.map(one_hot_label, num_parallel_calls = AUTOTUNE)\n",
    "val_ds = val_ds.map(one_hot_label, num_parallel_calls = AUTOTUNE)\n",
    "\n",
    "# Optimizes data pipeline with caching and prefetching for efficient training and validation\n",
    "train_ds = train_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "\n",
    "# Counts the number of images per class for further analysis or balancing\n",
    "NUM_IMAGES = []\n",
    "\n",
    "for label in class_names:\n",
    "    dir_name = \"/kaggle/input/alzheimers-mri-images/Processed Dataset/training/\" + label[:-2] + 'ed'\n",
    "    NUM_IMAGES.append(len([name for name in os.listdir(dir_name)]))\n",
    "\n",
    "# Outputs the number of images per class for review\n",
    "NUM_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.037746,
     "end_time": "2024-07-28T20:20:08.582974",
     "exception": false,
     "start_time": "2024-07-28T20:20:08.545228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defines a reusable convolutional block for the CNN model architecture\n",
    "def conv_block(filters):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.SeparableConv2D(filters, 3, activation = 'relu', padding = 'same'),\n",
    "        tf.keras.layers.SeparableConv2D(filters, 3, activation = 'relu', padding = 'same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPool2D()\n",
    "    ])\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.03783,
     "end_time": "2024-07-28T20:20:08.650541",
     "exception": false,
     "start_time": "2024-07-28T20:20:08.612711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defines a reusable dense block for the CNN model architecture\n",
    "def dense_block(units, dropout_rate):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units, activation = 'relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.041548,
     "end_time": "2024-07-28T20:20:08.721003",
     "exception": false,
     "start_time": "2024-07-28T20:20:08.679455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Builds the full CNN model using convolutional and dense blocks for multiclass classification\n",
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape = (*IMAGE_SIZE, 3)),  # Input layer with image dimensions\n",
    "\n",
    "        tf.keras.layers.Conv2D(16, 3, activation = 'relu', padding = 'same'),\n",
    "        tf.keras.layers.Conv2D(16, 3, activation = 'relu', padding = 'same'),\n",
    "\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        conv_block(32),\n",
    "        conv_block(64),\n",
    "        conv_block(128),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "        conv_block(256),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        dense_block(512, 0.7),\n",
    "        dense_block(128, 0.5),\n",
    "        dense_block(64, 0.3),\n",
    "\n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation = 'softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.669429,
     "end_time": "2024-07-28T20:20:09.419327",
     "exception": false,
     "start_time": "2024-07-28T20:20:08.749898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compiles the model within the chosen device strategy, specifying optimizer, loss, and metrics\n",
    "with strategy.scope():\n",
    "    model = build_model()\n",
    "    METRICS = [tf.keras.metrics.AUC(name = 'auc')]\n",
    "    model.compile(\n",
    "        optimizer = 'adam',\n",
    "        loss = tf.losses.CategoricalCrossentropy(),\n",
    "        metrics = METRICS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.038867,
     "end_time": "2024-07-28T20:20:09.546142",
     "exception": false,
     "start_time": "2024-07-28T20:20:09.507275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sets up learning rate scheduling, model checkpointing, and early stopping for robust training\n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 ** (epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "# Creates an exponential decay function for the learning rate (initial lr=0.01, decay steps=20)\n",
    "exponential_decay_fn = exponential_decay(0.01, 20)\n",
    "\n",
    "# Callbacks to update the learning rate according to the exponential decay schedule\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "# Callbacks to save the best model during training based on validation performance\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"tensorflow_alzheimer_model.keras\", save_best_only = True)\n",
    "\n",
    "# Callbacks to stop training early if validation performance does not improve for 10 epochs and restore best weights\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays a summary and diagram of the model architecture for verification\n",
    "model.summary()\n",
    "\n",
    "tf.keras.utils.plot_model(model, to_file = 'model.png', show_shapes = True, show_layer_names = True, show_dtype = True, dpi = 120)\n",
    "\n",
    "# Trains the model using the training and validation sets with callbacks for monitoring and early stopping\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds,\n",
    "    callbacks = [checkpoint_cb, early_stopping_cb, lr_scheduler],\n",
    "    epochs = EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 5.398647,
     "end_time": "2024-07-28T20:35:30.459313",
     "exception": false,
     "start_time": "2024-07-28T20:35:25.060666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plots training and validation AUC and loss to visualize model performance over epochs\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['auc', 'loss']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 5.531725,
     "end_time": "2024-07-28T20:35:51.184767",
     "exception": false,
     "start_time": "2024-07-28T20:35:45.653042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loads and prepares the test dataset for evaluation, including one-hot encoding and performance optimizations\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/kaggle/input/alzheimers-mri-images/Processed Dataset/test\",\n",
    "    image_size = IMAGE_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    ")\n",
    "test_ds = test_ds.map(one_hot_label, num_parallel_calls = AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "\n",
    "# Evaluates the trained model on the test dataset and outputs the results\n",
    "_ = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates predictions for the test set, computes and visualizes the confusion matrix as a percentage heatmap\n",
    "predictions = model.predict(test_ds)\n",
    "\n",
    "# Converts predictions to class labels\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Retrieves true labels\n",
    "y_real = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "y_real = np.argmax(y_real, axis=1)  # Converts one-hot labels to class indices\n",
    "\n",
    "# Computes confusion matrix\n",
    "cm = confusion_matrix(y_real, y_pred)\n",
    "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100  # Converts to percentage format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots confusion matrix\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(cm_percent, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays predicted probabilities, predicted class, and actual class for each test sample, indicating correctness\n",
    "for p, l in zip(predictions, y_real):\n",
    "    probs_percent = [f\"{prob*100:.2f}%\" for prob in p]  # Converts probabilities to percentage\n",
    "    predicted_class_idx = np.argmax(p)  # Index of the predicted class\n",
    "    predicted_class_name = class_names[predicted_class_idx]\n",
    "\n",
    "    print(f\"Predictions: {probs_percent} -> Predicted class: {predicted_class_name} (Class {predicted_class_idx}), Actual Label: {class_names[l]}\")\n",
    "\n",
    "    if predicted_class_idx == l:\n",
    "        print(\"Correct ✅\\n\")\n",
    "    else:\n",
    "        print(\"Incorrect ❌\\n\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6409027,
     "sourceId": 10349832,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "papermill": {
   "duration": 1055.236024,
   "end_time": "2024-07-28T20:36:27.017726",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-28T20:18:51.781702",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
